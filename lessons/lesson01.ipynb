{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 01: ‚õìÔ∏è Chains and üí¨ Chats with ü¶π‚Äç‚ôÄÔ∏è Placeholders\n",
    "\n",
    "Hi and welcome!\n",
    "\n",
    "(In case your're new to Juypter: This is a boring text cell. Stuff to read, and nothing to do.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">üëã Hello from beyond-chatting!\n",
       "Version: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>.0dev0\n",
       "\n",
       "    __                               __  \n",
       "   <span style=\"color: #800080; text-decoration-color: #800080\">/</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">_</span>  ___  __  ______  ____  ____/ <span style=\"color: #800080; text-decoration-color: #800080\">/</span>  \n",
       "  <span style=\"color: #800080; text-decoration-color: #800080\">/</span> __ \\<span style=\"color: #800080; text-decoration-color: #800080\">/</span> _ \\<span style=\"color: #800080; text-decoration-color: #800080\">/</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span> __ \\<span style=\"color: #800080; text-decoration-color: #800080\">/</span> __ \\<span style=\"color: #800080; text-decoration-color: #800080\">/</span> __  <span style=\"color: #800080; text-decoration-color: #800080\">/</span>   \n",
       " <span style=\"color: #800080; text-decoration-color: #800080\">/</span> <span style=\"color: #800080; text-decoration-color: #800080\">/_/</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span>  __/ <span style=\"color: #800080; text-decoration-color: #800080\">/_/</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span> <span style=\"color: #800080; text-decoration-color: #800080\">/_/</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span> <span style=\"color: #800080; text-decoration-color: #800080\">/_/</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span>    \n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">/_.___/</span>\\___/\\__, <span style=\"color: #800080; text-decoration-color: #800080\">/</span>\\____/__ <span style=\"color: #800080; text-decoration-color: #800080\">/_/</span>\\__,_/     \n",
       "  _____/ <span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">_</span>  ___/ _/ <span style=\"color: #800080; text-decoration-color: #800080\">/_/</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">_</span><span style=\"font-weight: bold\">(</span>_<span style=\"font-weight: bold\">)</span>___  ____ _\n",
       " <span style=\"color: #800080; text-decoration-color: #800080\">/</span> ___/ __ \\<span style=\"color: #800080; text-decoration-color: #800080\">/</span> __ `<span style=\"color: #800080; text-decoration-color: #800080\">/</span> __/ __/ <span style=\"color: #800080; text-decoration-color: #800080\">/</span> __ \\<span style=\"color: #800080; text-decoration-color: #800080\">/</span> __ `<span style=\"color: #800080; text-decoration-color: #800080\">/</span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080\">/</span> <span style=\"color: #800080; text-decoration-color: #800080\">/__/</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span> <span style=\"color: #800080; text-decoration-color: #800080\">/_/</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span> <span style=\"color: #800080; text-decoration-color: #800080\">/_/</span> <span style=\"color: #800080; text-decoration-color: #800080\">/_/</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span> <span style=\"color: #800080; text-decoration-color: #800080\">/_/</span> <span style=\"color: #800080; text-decoration-color: #800080\">/</span> \n",
       "\\___/_/ <span style=\"color: #800080; text-decoration-color: #800080\">/_/</span>\\__,_/\\__/\\__/_/_/ <span style=\"color: #800080; text-decoration-color: #800080\">/_/</span>\\__, <span style=\"color: #800080; text-decoration-color: #800080\">/</span>  \n",
       "                                <span style=\"color: #800080; text-decoration-color: #800080\">/____/</span>   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "üëã Hello from beyond-chatting!\n",
       "Version: \u001b[1;36m0.1\u001b[0m.0dev0\n",
       "\n",
       "    __                               __  \n",
       "   \u001b[35m/\u001b[0m \u001b[35m/\u001b[0m\u001b[95m_\u001b[0m  ___  __  ______  ____  ____/ \u001b[35m/\u001b[0m  \n",
       "  \u001b[35m/\u001b[0m __ \\\u001b[35m/\u001b[0m _ \\\u001b[35m/\u001b[0m \u001b[35m/\u001b[0m \u001b[35m/\u001b[0m \u001b[35m/\u001b[0m __ \\\u001b[35m/\u001b[0m __ \\\u001b[35m/\u001b[0m __  \u001b[35m/\u001b[0m   \n",
       " \u001b[35m/\u001b[0m \u001b[35m/_/\u001b[0m \u001b[35m/\u001b[0m  __/ \u001b[35m/_/\u001b[0m \u001b[35m/\u001b[0m \u001b[35m/_/\u001b[0m \u001b[35m/\u001b[0m \u001b[35m/\u001b[0m \u001b[35m/\u001b[0m \u001b[35m/\u001b[0m \u001b[35m/_/\u001b[0m \u001b[35m/\u001b[0m    \n",
       "\u001b[35m/_.___/\u001b[0m\\___/\\__, \u001b[35m/\u001b[0m\\____/__ \u001b[35m/_/\u001b[0m\\__,_/     \n",
       "  _____/ \u001b[35m/\u001b[0m\u001b[95m_\u001b[0m  ___/ _/ \u001b[35m/_/\u001b[0m \u001b[35m/\u001b[0m\u001b[95m_\u001b[0m\u001b[1m(\u001b[0m_\u001b[1m)\u001b[0m___  ____ _\n",
       " \u001b[35m/\u001b[0m ___/ __ \\\u001b[35m/\u001b[0m __ `\u001b[35m/\u001b[0m __/ __/ \u001b[35m/\u001b[0m __ \\\u001b[35m/\u001b[0m __ `\u001b[35m/\u001b[0m\n",
       "\u001b[35m/\u001b[0m \u001b[35m/__/\u001b[0m \u001b[35m/\u001b[0m \u001b[35m/\u001b[0m \u001b[35m/\u001b[0m \u001b[35m/_/\u001b[0m \u001b[35m/\u001b[0m \u001b[35m/_/\u001b[0m \u001b[35m/_/\u001b[0m \u001b[35m/\u001b[0m \u001b[35m/\u001b[0m \u001b[35m/\u001b[0m \u001b[35m/\u001b[0m \u001b[35m/_/\u001b[0m \u001b[35m/\u001b[0m \n",
       "\\___/_/ \u001b[35m/_/\u001b[0m\\__,_/\\__/\\__/_/_/ \u001b[35m/_/\u001b[0m\\__, \u001b[35m/\u001b[0m  \n",
       "                                \u001b[35m/____/\u001b[0m   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is a code cell. It can be executed. Just klick the ‚ñ∂Ô∏è play button (at the left) to do so.\n",
    "import rich\n",
    "from beyond_chatting import LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To work with this tutorial, you'll need to execute all its code cells.\n"
     ]
    }
   ],
   "source": [
    "print(\"To work with this tutorial, you'll need to execute all its code cells.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">I encourage you to <span style=\"font-weight: bold\">play with the code</span> by copying, modifying and imitating it!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "I encourage you to \u001b[1mplay with the code\u001b[0m by copying, modifying and imitating it!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rich.print(\"I encourage you to [bold]play with the code[/bold] by copying, modifying and imitating it!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Learning Objectives\n",
    "\n",
    "You'll **practice** in this lesson:\n",
    "\n",
    "* how to prompt an LLM **programmatically**\n",
    "* how to generalize prompts by using **placeholders** (named and unnamed slots)\n",
    "* how to **chain LLM-instructions** by using one step's output as the next step's input\n",
    "* how to implement **workflows where each steps sees the entire history** by mimicking chats "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Prompting via Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c894d7db695a44d1ae91dd6cc6a337e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">ü§ñ Found local model llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.2</span>-3b-instruct at <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">http://localhost:8000/v1/</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "ü§ñ Found local model llama-\u001b[1;36m3.2\u001b[0m-3b-instruct at \u001b[4;94mhttp://localhost:8000/v1/\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's initialize our first LLM\n",
    "llm = LLM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">I am <span style=\"font-weight: bold\">llama-</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.2</span><span style=\"font-weight: bold\">-3b-instruct</span>, a large language model.\n",
       "I am served at <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">http://localhost:8000/v1/.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "I am \u001b[1mllama-\u001b[0m\u001b[1;36m3.2\u001b[0m\u001b[1m-3b-instruct\u001b[0m, a large language model.\n",
       "I am served at \u001b[4;94mhttp://localhost:8000/v1/.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm.who_am_i()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello!'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"Say hello!\")\n",
    "#   ^^^prompt^^^ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Hello!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Hello!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Or, similarly:\n",
    "answer = llm(\"Say hello!\")  # Store the generated answer in a variable\n",
    "rich.print(answer)  # Print the answer (gives us automatic line breaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Yes, it's perfectly fine for an AI assistant to introduce itself with <span style=\"color: #008000; text-decoration-color: #008000\">\"Hello!\"</span> or a more formal greeting like \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\"Hello, I'm [Assistant Name]. How can I assist you today?\"</span> or the brand name if available.\n",
       "\n",
       "However, there are some potential drawbacks to consider:\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. Lack of personalization: A simple <span style=\"color: #008000; text-decoration-color: #008000\">\"Hello!\"</span> might come across as impersonal or robotic.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. Limited context: Without additional context, it can be difficult for users to understand the nature of the \n",
       "interaction and the capabilities of the AI assistant.\n",
       "\n",
       "To mitigate these issues, you could consider adding more context or personalization to the introduction, such as:\n",
       "\n",
       "- Including the name of the assistant or the brand\n",
       "- Adding a brief message about the assistant's capabilities or purpose\n",
       "- Using a more friendly or approachable tone\n",
       "\n",
       "Ultimately, the key is to find a balance between friendliness and professionalism. You can experiment with \n",
       "different greetings to see what works best for your AI assistant and your users.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Yes, it's perfectly fine for an AI assistant to introduce itself with \u001b[32m\"Hello!\"\u001b[0m or a more formal greeting like \n",
       "\u001b[32m\"Hello, I'm \u001b[0m\u001b[32m[\u001b[0m\u001b[32mAssistant Name\u001b[0m\u001b[32m]\u001b[0m\u001b[32m. How can I assist you today?\"\u001b[0m or the brand name if available.\n",
       "\n",
       "However, there are some potential drawbacks to consider:\n",
       "\n",
       "\u001b[1;36m1\u001b[0m. Lack of personalization: A simple \u001b[32m\"Hello!\"\u001b[0m might come across as impersonal or robotic.\n",
       "\u001b[1;36m2\u001b[0m. Limited context: Without additional context, it can be difficult for users to understand the nature of the \n",
       "interaction and the capabilities of the AI assistant.\n",
       "\n",
       "To mitigate these issues, you could consider adding more context or personalization to the introduction, such as:\n",
       "\n",
       "- Including the name of the assistant or the brand\n",
       "- Adding a brief message about the assistant's capabilities or purpose\n",
       "- Using a more friendly or approachable tone\n",
       "\n",
       "Ultimately, the key is to find a balance between friendliness and professionalism. You can experiment with \n",
       "different greetings to see what works best for your AI assistant and your users.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Then we can do:\n",
    "assessment = llm(f\"Is it OK for an AI assistant to introduce itself with: \\\"{answer}\\\"?\")\n",
    "rich.print(assessment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üòØ Wait... what happened here?\n",
    "\n",
    "\n",
    "<details><summary>Explanation</summary>\n",
    "\n",
    "We've asked the LLM to assess the answer it has given us before.\n",
    "\n",
    "```python\n",
    "assessment = llm(f\"Is it OK for an AI assistant to introduce itself with: \\\"{answer}\\\"?\")\n",
    "# NOTE:          ^ the f indicates that the string contains a placeholder:  ^^^^^^^^\n",
    "#                this placeholder will be replaced with the value of the variable \"answer\"\n",
    "rich.print(assessment)\n",
    "```\n",
    "\n",
    "‚Äì Our first pipeline. ü•≥\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Chains with Placeholders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Original introduction: <span style=\"color: #008000; text-decoration-color: #008000\">\"I'm an artificial intelligence model designed to provide information, answer questions, and</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">engage in conversation to the best of my abilities. I don't have a personal name, but I'm here to assist you with </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">any topic or question you'd like to discuss.\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Original introduction: \u001b[32m\"I'm an artificial intelligence model designed to provide information, answer questions, and\u001b[0m\n",
       "\u001b[32mengage in conversation to the best of my abilities. I don't have a personal name, but I'm here to assist you with \u001b[0m\n",
       "\u001b[32many topic or question you'd like to discuss.\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The introduction you provided is not misleading. Here's why:\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. **Transparency**: The introduction clearly states that the AI assistant doesn't have a personal name. This sets \n",
       "clear expectations for the user.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. **Accurate representation**: The introduction accurately represents the AI assistant's capabilities, including \n",
       "providing information, answering questions, and engaging in conversation.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. **No false promises**: The introduction does not promise any specific outcomes or results that may be difficult \n",
       "to achieve. It simply states the AI's capabilities and limitations.\n",
       "\n",
       "However, some might argue that the introduction could be improved by:\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. **Providing context**: Adding a brief explanation of the AI assistant's purpose, scope, or area of expertise \n",
       "could help users understand the context and limitations of the assistance.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. **Clearly stating the limitations**: While the introduction states that the AI doesn't have a personal name, it \n",
       "might be beneficial to explicitly state any limitations or potential biases of the AI assistant.\n",
       "\n",
       "A revised introduction might look like this:\n",
       "\n",
       "\"Hello! I'm an AI assistant designed to provide general information and answer questions to the best of my \n",
       "abilities. I don't have a personal name, but I'm here to assist you with any topic or question you'd like to \n",
       "discuss. Please keep in mind that I\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The introduction you provided is not misleading. Here's why:\n",
       "\n",
       "\u001b[1;36m1\u001b[0m. **Transparency**: The introduction clearly states that the AI assistant doesn't have a personal name. This sets \n",
       "clear expectations for the user.\n",
       "\u001b[1;36m2\u001b[0m. **Accurate representation**: The introduction accurately represents the AI assistant's capabilities, including \n",
       "providing information, answering questions, and engaging in conversation.\n",
       "\u001b[1;36m3\u001b[0m. **No false promises**: The introduction does not promise any specific outcomes or results that may be difficult \n",
       "to achieve. It simply states the AI's capabilities and limitations.\n",
       "\n",
       "However, some might argue that the introduction could be improved by:\n",
       "\n",
       "\u001b[1;36m1\u001b[0m. **Providing context**: Adding a brief explanation of the AI assistant's purpose, scope, or area of expertise \n",
       "could help users understand the context and limitations of the assistance.\n",
       "\u001b[1;36m2\u001b[0m. **Clearly stating the limitations**: While the introduction states that the AI doesn't have a personal name, it \n",
       "might be beneficial to explicitly state any limitations or potential biases of the AI assistant.\n",
       "\n",
       "A revised introduction might look like this:\n",
       "\n",
       "\"Hello! I'm an AI assistant designed to provide general information and answer questions to the best of my \n",
       "abilities. I don't have a personal name, but I'm here to assist you with any topic or question you'd like to \n",
       "discuss. Please keep in mind that I\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Same pipeline as before, no in one cell, using more variables to structure the code, slightly different prompts:\n",
    "\n",
    "prompt_introduction = \"Introduce yourself, succinctly.\"\n",
    "answer = llm(prompt_introduction)\n",
    "rich.print(f\"Original introduction: \\\"{answer}\\\"\")\n",
    "\n",
    "prompt_assessment = f\"Is it misleading for an AI assistant to introduce themselves with: \\\"{answer}\\\"?\"\n",
    "assessment = llm(prompt_assessment)\n",
    "rich.print(assessment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The introduction you provided is not misleading. Here's why:\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. **Transparency**: The introduction clearly states that the AI assistant doesn't have a personal name. This sets \n",
       "clear expectations for the user.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. **Accurate representation**: The introduction accurately represents the AI assistant's capabilities, including \n",
       "providing information, answering questions, and engaging in conversation.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. **No false promises**: The introduction does not promise any specific outcomes or results that may be difficult \n",
       "to achieve. It simply states the AI's capabilities and limitations.\n",
       "\n",
       "However, some might argue that the introduction could be improved by:\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. **Providing context**: Adding a brief explanation of the AI assistant's purpose, scope, or area of expertise \n",
       "could help users understand the context and limitations of the assistance.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. **Clearly stating the limitations**: While the introduction states that the AI doesn't have a personal name, it \n",
       "might be beneficial to explicitly state any limitations or potential biases of the AI assistant.\n",
       "\n",
       "A revised introduction might look like this:\n",
       "\n",
       "\"Hello! I'm an AI assistant designed to provide general information and answer questions to the best of my \n",
       "abilities. I don't have a personal name, but I'm here to assist you with any topic or question you'd like to \n",
       "discuss. Please keep in mind that I\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The introduction you provided is not misleading. Here's why:\n",
       "\n",
       "\u001b[1;36m1\u001b[0m. **Transparency**: The introduction clearly states that the AI assistant doesn't have a personal name. This sets \n",
       "clear expectations for the user.\n",
       "\u001b[1;36m2\u001b[0m. **Accurate representation**: The introduction accurately represents the AI assistant's capabilities, including \n",
       "providing information, answering questions, and engaging in conversation.\n",
       "\u001b[1;36m3\u001b[0m. **No false promises**: The introduction does not promise any specific outcomes or results that may be difficult \n",
       "to achieve. It simply states the AI's capabilities and limitations.\n",
       "\n",
       "However, some might argue that the introduction could be improved by:\n",
       "\n",
       "\u001b[1;36m1\u001b[0m. **Providing context**: Adding a brief explanation of the AI assistant's purpose, scope, or area of expertise \n",
       "could help users understand the context and limitations of the assistance.\n",
       "\u001b[1;36m2\u001b[0m. **Clearly stating the limitations**: While the introduction states that the AI doesn't have a personal name, it \n",
       "might be beneficial to explicitly state any limitations or potential biases of the AI assistant.\n",
       "\n",
       "A revised introduction might look like this:\n",
       "\n",
       "\"Hello! I'm an AI assistant designed to provide general information and answer questions to the best of my \n",
       "abilities. I don't have a personal name, but I'm here to assist you with any topic or question you'd like to \n",
       "discuss. Please keep in mind that I\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Some frameworks allow for an elegant style\n",
    "\n",
    "prompt_introduction = \"Introduce yourself, succinctly.\"\n",
    "prompt_assessment = \"Is it misleading for an AI assistant to introduce themselves with: \\\"{}\\\"?\"\n",
    "#                                                               unnamed placeholder slot: ^^\n",
    "\n",
    "answer = llm(prompt_introduction) | llm(prompt_assessment) \n",
    "#            output from here ...   ... goes in slot here\n",
    "rich.print(assessment)\n",
    "\n",
    "# This only prints the final answer (assessment). \n",
    "# Do you see why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Case Study:** Chain-of-Thought (CoT) Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° Let's use the **placeholder technique** to set up a chain-of-thought pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's a problem from the cognitive reflection test:\n",
    "problem = \"If it takes 4 cooks 4 minutes to make 4 sandwichs, how long would it take 8 cooks to make 8 sandwichs?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 minute'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can our LLM solve it straightaway?\n",
    "llm(f\"{problem}\\n Just provide the number of minutes, no reasoning or explanation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">It will take <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> cooks <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span> minutes to make <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> sandwiches.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "It will take \u001b[1;36m8\u001b[0m cooks \u001b[1;36m32\u001b[0m minutes to make \u001b[1;36m8\u001b[0m sandwiches.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's give chain-of-thought with revision a try:\n",
    "\n",
    "from beyond_chatting import inputs\n",
    "\n",
    "prompt_solve = \"\"\"\n",
    "Solve the following problem:\n",
    "\n",
    "{}\n",
    "\n",
    "In your answer, restate the problem before providing your solution.\n",
    "\"\"\"\n",
    "\n",
    "prompt_revise = \"\"\"\n",
    "Please carefully assess and improve the solution provided, if required:\n",
    "\n",
    "{}\n",
    "\n",
    "In your answer, restate the problem before providing your solution\n",
    "\"\"\"\n",
    "\n",
    "prompt_answer = \"\"\"\n",
    "Sum up the following solution:\n",
    "\n",
    "{}\n",
    "\n",
    "Just provide the correct answer to the problem.\n",
    "\"\"\"\n",
    "\n",
    "answer = inputs(problem) | llm(prompt_solve) | llm(prompt_revise) | llm(prompt_answer)\n",
    "rich.print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the above pipeline to work, it was essential that we've asked the LLM to repeat the initial problem in its answers. Otherwise, the LLM would not have seen the problem when addressing the second (revise) or third (answer) query.\n",
    "\n",
    "```python\n",
    "inputs(problem) | llm(prompt_solve) | llm(prompt_revise) | llm(prompt_answer)\n",
    "#          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ>‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ>‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ>‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "#          output is            output is            output is\n",
    "#          only input           only input           only input\n",
    "```\n",
    "\n",
    "But sometimes we rather want this (e.g., to make SURE that the original, undistorted problem statement is available while revising the initial solution):\n",
    "\n",
    "```python\n",
    "inputs(problem) | llm(prompt_solve) | llm(prompt_revise) | llm(prompt_answer)\n",
    "#          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ>‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ>‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ>‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "#          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    \n",
    "#                prompt_revise sees \n",
    "#                 initial problem\n",
    "#          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ>‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    \n",
    "#                             prompt_answer sees \n",
    "#                              initial problem\n",
    "```\n",
    "We can implement this so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"font-weight: bold\">Solution:</span> To solve this problem, let's analyze the situation:\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> cooks can make <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> sandwiches in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> minutes.\n",
       "\n",
       "If we multiply both the number of cooks and the number of sandwiches by <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, we get:\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> cooks can make <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> sandwiches.\n",
       "\n",
       "Since the number of cooks and the number of sandwiches are directly related, the time it takes will be the same \n",
       "proportion as the number of cooks and sandwiches.\n",
       "\n",
       "In this case, the number of cooks has doubled, so the time it takes will also double.\n",
       "\n",
       "Therefore, if it takes <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> cooks <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> minutes to make <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> sandwiches, it will take <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> cooks <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> minutes to make <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> sandwiches.\n",
       "\n",
       "<span style=\"font-weight: bold\">Revision:</span> The solution is mostly correct, but it's a bit simplistic and doesn't fully address the relationship \n",
       "between the number of cooks and the time it takes to make sandwiches. Here's an improved solution:\n",
       "\n",
       "Let's analyze the situation:\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> cooks can make <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> sandwiches in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> minutes. This means that each cook can make <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> sandwich in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> minutes.\n",
       "\n",
       "If we multiply both the number of cooks and the number of sandwiches by <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, we get:\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> cooks can make <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> sandwiches.\n",
       "\n",
       "Since each cook can make <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> sandwich in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> minutes, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> cooks can make <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> sandwiches in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> minutes. This is because the \n",
       "number of cooks is now <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> times the original number, and the number of sandwiches is also <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> times the original \n",
       "number.\n",
       "\n",
       "However, the time it takes to make sandwiches is determined by the time it takes for each cook to make a sandwich. \n",
       "Since each cook can make <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> sandwich in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> minutes, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> cooks will still take <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> minutes to make <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> sandwiches.\n",
       "\n",
       "Therefore, if it takes <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> cooks <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> minutes to make <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> sandwiches, it will indeed take <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> cooks <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> minutes to make <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> \n",
       "sandwiches.\n",
       "\n",
       "The key insight here is that the number of cooks and the number of\n",
       "\n",
       "<span style=\"font-weight: bold\">Answer:</span> It would take <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> cooks <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> minutes to make <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> sandwiches.\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[1mSolution:\u001b[0m To solve this problem, let's analyze the situation:\n",
       "\n",
       "\u001b[1;36m4\u001b[0m cooks can make \u001b[1;36m4\u001b[0m sandwiches in \u001b[1;36m4\u001b[0m minutes.\n",
       "\n",
       "If we multiply both the number of cooks and the number of sandwiches by \u001b[1;36m2\u001b[0m, we get:\n",
       "\n",
       "\u001b[1;36m8\u001b[0m cooks can make \u001b[1;36m8\u001b[0m sandwiches.\n",
       "\n",
       "Since the number of cooks and the number of sandwiches are directly related, the time it takes will be the same \n",
       "proportion as the number of cooks and sandwiches.\n",
       "\n",
       "In this case, the number of cooks has doubled, so the time it takes will also double.\n",
       "\n",
       "Therefore, if it takes \u001b[1;36m4\u001b[0m cooks \u001b[1;36m4\u001b[0m minutes to make \u001b[1;36m4\u001b[0m sandwiches, it will take \u001b[1;36m8\u001b[0m cooks \u001b[1;36m8\u001b[0m minutes to make \u001b[1;36m8\u001b[0m sandwiches.\n",
       "\n",
       "\u001b[1mRevision:\u001b[0m The solution is mostly correct, but it's a bit simplistic and doesn't fully address the relationship \n",
       "between the number of cooks and the time it takes to make sandwiches. Here's an improved solution:\n",
       "\n",
       "Let's analyze the situation:\n",
       "\n",
       "\u001b[1;36m4\u001b[0m cooks can make \u001b[1;36m4\u001b[0m sandwiches in \u001b[1;36m4\u001b[0m minutes. This means that each cook can make \u001b[1;36m1\u001b[0m sandwich in \u001b[1;36m4\u001b[0m minutes.\n",
       "\n",
       "If we multiply both the number of cooks and the number of sandwiches by \u001b[1;36m2\u001b[0m, we get:\n",
       "\n",
       "\u001b[1;36m8\u001b[0m cooks can make \u001b[1;36m8\u001b[0m sandwiches.\n",
       "\n",
       "Since each cook can make \u001b[1;36m1\u001b[0m sandwich in \u001b[1;36m4\u001b[0m minutes, \u001b[1;36m8\u001b[0m cooks can make \u001b[1;36m8\u001b[0m sandwiches in \u001b[1;36m4\u001b[0m minutes. This is because the \n",
       "number of cooks is now \u001b[1;36m2\u001b[0m times the original number, and the number of sandwiches is also \u001b[1;36m2\u001b[0m times the original \n",
       "number.\n",
       "\n",
       "However, the time it takes to make sandwiches is determined by the time it takes for each cook to make a sandwich. \n",
       "Since each cook can make \u001b[1;36m1\u001b[0m sandwich in \u001b[1;36m4\u001b[0m minutes, \u001b[1;36m8\u001b[0m cooks will still take \u001b[1;36m4\u001b[0m minutes to make \u001b[1;36m8\u001b[0m sandwiches.\n",
       "\n",
       "Therefore, if it takes \u001b[1;36m4\u001b[0m cooks \u001b[1;36m4\u001b[0m minutes to make \u001b[1;36m4\u001b[0m sandwiches, it will indeed take \u001b[1;36m8\u001b[0m cooks \u001b[1;36m4\u001b[0m minutes to make \u001b[1;36m8\u001b[0m \n",
       "sandwiches.\n",
       "\n",
       "The key insight here is that the number of cooks and the number of\n",
       "\n",
       "\u001b[1mAnswer:\u001b[0m It would take \u001b[1;36m8\u001b[0m cooks \u001b[1;36m4\u001b[0m minutes to make \u001b[1;36m8\u001b[0m sandwiches.\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# INPUTS\n",
    "\n",
    "problem = \"If it takes 4 cooks 4 minutes to make 4 sandwichs, how long would it take 8 cooks to make 8 sandwichs?\"\n",
    "\n",
    "# PROMPTS\n",
    "\n",
    "prompt_solve = \"\"\"\n",
    "Solve the following problem:\n",
    "\n",
    "Problem: {problem}\n",
    "\"\"\"\n",
    "\n",
    "prompt_revise = \"\"\"\n",
    "Please carefully assess and improve the solution to the given problem, if required:\n",
    "\n",
    "Problem: {problem}\n",
    "\n",
    "Solution: {solution}\n",
    "\"\"\"\n",
    "\n",
    "prompt_answer = \"\"\"\n",
    "Extract the answer from the following solution:\n",
    "\n",
    "Problem: {problem}\n",
    "\n",
    "Solution: {revision}\n",
    "\n",
    "Just provide the short answer to the problem according to the solution.\n",
    "\"\"\"\n",
    "\n",
    "# CHAIN\n",
    "\n",
    "solution = llm(prompt_solve.format(problem=problem))\n",
    "#             ^^^^^replacing placeholders here^^^^^^ \n",
    "#                  before passing prompt to LLM\n",
    "revision = llm(prompt_revise.format(problem=problem, solution=solution))\n",
    "answer = llm(prompt_answer.format(problem=problem, revision=revision))\n",
    "\n",
    "# OUTPUT\n",
    "\n",
    "rich.print(f\"\"\"\n",
    "\n",
    "[bold]Solution:[/bold] {solution}\n",
    "\n",
    "[bold]Revision:[/bold] {revision}\n",
    "\n",
    "[bold]Answer:[/bold] {answer}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"font-weight: bold\">Solution:</span> To address this question, let's break down the concept of <span style=\"color: #008000; text-decoration-color: #008000\">\"progressive\"</span> in the context of politics and \n",
       "social issues. The term <span style=\"color: #008000; text-decoration-color: #008000\">\"progressive\"</span> generally refers to a political ideology or agenda that emphasizes social and\n",
       "economic change, often with an emphasis on equality, justice, and human rights.\n",
       "\n",
       "In the context of education, progressive policies often focus on individualized learning, student-centered \n",
       "approaches, and community-involvement. A progressive attitude might prioritize the needs and experiences of \n",
       "marginalized or underrepresented groups, such as low-income families or students of color.\n",
       "\n",
       "Now, let's apply this framework to the demand for states to fund voluntary mentorship programs for parents doing \n",
       "homeschooling:\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. **Inclusivity and access**: The demand for funding voluntary mentorship programs for homeschooling parents can \n",
       "be seen as a progressive push for inclusivity and access to quality education. Homeschooling is often associated \n",
       "with marginalized or underrepresented groups, and providing resources to support this type of education can be seen\n",
       "as a progressive effort to address historical and systemic inequalities.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. **Community involvement**: Progressive policies often emphasize community involvement and collaboration. By \n",
       "funding mentorship programs, states can encourage community partnerships and foster a sense of shared \n",
       "responsibility for supporting families who choose to homeschool their children.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>. **Empower\n",
       "\n",
       "<span style=\"font-weight: bold\">Revision:</span> Here's an improved version of the solution:\n",
       "\n",
       "Problem: Is <span style=\"color: #008000; text-decoration-color: #008000\">'progressive'</span> an appropriate characterization for the demand that states ought to fund voluntary \n",
       "mentorship programs for parents doing homeschooling?\n",
       "\n",
       "Solution: To address this question, let's break down the concept of <span style=\"color: #008000; text-decoration-color: #008000\">\"progressive\"</span> in the context of politics and \n",
       "social issues. The term <span style=\"color: #008000; text-decoration-color: #008000\">\"progressive\"</span> generally refers to a political ideology or agenda that emphasizes social and\n",
       "economic change, often with an emphasis on equality, justice, and human rights.\n",
       "\n",
       "In the context of education, progressive policies often focus on individualized learning, student-centered \n",
       "approaches, and community-involvement. A progressive attitude might prioritize the needs and experiences of \n",
       "marginalized or underrepresented groups, such as low-income families or students of color.\n",
       "\n",
       "Now, let's apply this framework to the demand for funding voluntary mentorship programs for homeschooling parents:\n",
       "\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>.  **Inclusivity and access**: The demand for funding voluntary mentorship programs for homeschooling parents can \n",
       "be seen as a progressive push for inclusivity and access to quality education. Homeschooling is often associated \n",
       "with marginalized or underrepresented groups, and providing resources to support this type of education can help \n",
       "address historical and systemic inequalities. By recognizing the potential benefits of homeschooling for these \n",
       "groups, funding mentorship programs would\n",
       "\n",
       "<span style=\"font-weight: bold\">Answer:</span> Yes, <span style=\"color: #008000; text-decoration-color: #008000\">'progressive'</span> is an appropriate characterization for the demand that states ought to fund voluntary \n",
       "mentorship programs for parents doing homeschooling.\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[1mSolution:\u001b[0m To address this question, let's break down the concept of \u001b[32m\"progressive\"\u001b[0m in the context of politics and \n",
       "social issues. The term \u001b[32m\"progressive\"\u001b[0m generally refers to a political ideology or agenda that emphasizes social and\n",
       "economic change, often with an emphasis on equality, justice, and human rights.\n",
       "\n",
       "In the context of education, progressive policies often focus on individualized learning, student-centered \n",
       "approaches, and community-involvement. A progressive attitude might prioritize the needs and experiences of \n",
       "marginalized or underrepresented groups, such as low-income families or students of color.\n",
       "\n",
       "Now, let's apply this framework to the demand for states to fund voluntary mentorship programs for parents doing \n",
       "homeschooling:\n",
       "\n",
       "\u001b[1;36m1\u001b[0m. **Inclusivity and access**: The demand for funding voluntary mentorship programs for homeschooling parents can \n",
       "be seen as a progressive push for inclusivity and access to quality education. Homeschooling is often associated \n",
       "with marginalized or underrepresented groups, and providing resources to support this type of education can be seen\n",
       "as a progressive effort to address historical and systemic inequalities.\n",
       "\u001b[1;36m2\u001b[0m. **Community involvement**: Progressive policies often emphasize community involvement and collaboration. By \n",
       "funding mentorship programs, states can encourage community partnerships and foster a sense of shared \n",
       "responsibility for supporting families who choose to homeschool their children.\n",
       "\u001b[1;36m3\u001b[0m. **Empower\n",
       "\n",
       "\u001b[1mRevision:\u001b[0m Here's an improved version of the solution:\n",
       "\n",
       "Problem: Is \u001b[32m'progressive'\u001b[0m an appropriate characterization for the demand that states ought to fund voluntary \n",
       "mentorship programs for parents doing homeschooling?\n",
       "\n",
       "Solution: To address this question, let's break down the concept of \u001b[32m\"progressive\"\u001b[0m in the context of politics and \n",
       "social issues. The term \u001b[32m\"progressive\"\u001b[0m generally refers to a political ideology or agenda that emphasizes social and\n",
       "economic change, often with an emphasis on equality, justice, and human rights.\n",
       "\n",
       "In the context of education, progressive policies often focus on individualized learning, student-centered \n",
       "approaches, and community-involvement. A progressive attitude might prioritize the needs and experiences of \n",
       "marginalized or underrepresented groups, such as low-income families or students of color.\n",
       "\n",
       "Now, let's apply this framework to the demand for funding voluntary mentorship programs for homeschooling parents:\n",
       "\n",
       "\u001b[1;36m1\u001b[0m.  **Inclusivity and access**: The demand for funding voluntary mentorship programs for homeschooling parents can \n",
       "be seen as a progressive push for inclusivity and access to quality education. Homeschooling is often associated \n",
       "with marginalized or underrepresented groups, and providing resources to support this type of education can help \n",
       "address historical and systemic inequalities. By recognizing the potential benefits of homeschooling for these \n",
       "groups, funding mentorship programs would\n",
       "\n",
       "\u001b[1mAnswer:\u001b[0m Yes, \u001b[32m'progressive'\u001b[0m is an appropriate characterization for the demand that states ought to fund voluntary \n",
       "mentorship programs for parents doing homeschooling.\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Try this out with another problem!\n",
    "\n",
    "problem = \"Is 'progressive' an appropriate charaterization for the demand that states ought to fund voluntary mentorship programs for parents doing homeschooling?\"\n",
    "\n",
    "# CHAIN\n",
    "\n",
    "solution = llm(prompt_solve.format(problem=problem))\n",
    "revision = llm(prompt_revise.format(problem=problem, solution=solution))\n",
    "answer = llm(prompt_answer.format(problem=problem, revision=revision))\n",
    "\n",
    "# OUTPUT\n",
    "\n",
    "rich.print(f\"\"\"\n",
    "\n",
    "[bold]Solution:[/bold] {solution}\n",
    "\n",
    "[bold]Revision:[/bold] {revision}\n",
    "\n",
    "[bold]Answer:[/bold] {answer}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keeping Chat History in the LLM's Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">üèÅ Staring new üí¨ chat session:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "üèÅ Staring new üí¨ chat session:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">üë§ User:</span> What's the name of biggest city in California?\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1müë§ User:\u001b[0m What's the name of biggest city in California?\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">ü§ñ Assistant:</span> The largest city in California is Los Angeles.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mü§ñ Assistant:\u001b[0m The largest city in California is Los Angeles.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">üë§ User:</span> What is the most popular baseball club in <span style=\"font-weight: bold\">[</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1müë§ User:\u001b[0m What is the most popular baseball club in \u001b[1m[\u001b[0m\u001b[33m...\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">ü§ñ Assistant:</span> The most popular baseball team in the Los <span style=\"font-weight: bold\">[</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mü§ñ Assistant:\u001b[0m The most popular baseball team in the Los \u001b[1m[\u001b[0m\u001b[33m...\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The most popular baseball team in the Los Angeles area is the Los Angeles Dodgers.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "The most popular baseball team in the Los Angeles area is the Los Angeles Dodgers.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A bare LLM can only work with what it sees in its current context.\n",
    "# Chat models may have, besides the current prompt (instruction), the entire chat history in their context.\n",
    "\n",
    "with llm.session() as chat:  # This starts a new chat\n",
    "\n",
    "#>>>Indent for as long as we stay in this chat session \n",
    "\n",
    "    chat.ask(\"What's the name of biggest city in California? \")\n",
    "    answer = chat.ask(\"What is the most popular baseball club in that city'?\")\n",
    "\n",
    "#<<<Dedent to end the chat session\n",
    "\n",
    "rich.print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">üèÅ Staring new üí¨ chat session:\n",
       "</pre>\n"
      ],
      "text/plain": [
       "üèÅ Staring new üí¨ chat session:\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">üë§ User:</span> Consider the following problem: If it takes <span style=\"font-weight: bold\">[</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1müë§ User:\u001b[0m Consider the following problem: If it takes \u001b[1m[\u001b[0m\u001b[33m...\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">ü§ñ Assistant:</span> Characterization of the problem: This is a <span style=\"font-weight: bold\">[</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mü§ñ Assistant:\u001b[0m Characterization of the problem: This is a \u001b[1m[\u001b[0m\u001b[33m...\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">üë§ User:</span> Now, solve the above problem, taking into <span style=\"font-weight: bold\">[</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1müë§ User:\u001b[0m Now, solve the above problem, taking into \u001b[1m[\u001b[0m\u001b[33m...\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">ü§ñ Assistant:</span> To solve this problem, let's consider the <span style=\"font-weight: bold\">[</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mü§ñ Assistant:\u001b[0m To solve this problem, let's consider the \u001b[1m[\u001b[0m\u001b[33m...\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">üë§ User:</span> Please carefully assess and improve the <span style=\"font-weight: bold\">[</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1müë§ User:\u001b[0m Please carefully assess and improve the \u001b[1m[\u001b[0m\u001b[33m...\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">ü§ñ Assistant:</span> Upon re-examining the solution, I realized <span style=\"font-weight: bold\">[</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mü§ñ Assistant:\u001b[0m Upon re-examining the solution, I realized \u001b[1m[\u001b[0m\u001b[33m...\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">üë§ User:</span> Finally, extract the answer from the revised <span style=\"font-weight: bold\">[</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1müë§ User:\u001b[0m Finally, extract the answer from the revised \u001b[1m[\u001b[0m\u001b[33m...\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">ü§ñ Assistant:</span> Based on the revised solution, we can <span style=\"font-weight: bold\">[</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mü§ñ Assistant:\u001b[0m Based on the revised solution, we can \u001b[1m[\u001b[0m\u001b[33m...\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Based on the revised solution, we can conclude that:\n",
       "\n",
       "If <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> cooks can make <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> sandwiches in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> minutes, then <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> cooks can make <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> sandwiches in <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> minutes.\n",
       "\n",
       "This is because the work rate per cook remains constant, and the number of cooks is simply doubled. Therefore, the \n",
       "time required to make <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span> sandwiches remains the same, which is <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> minutes.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Based on the revised solution, we can conclude that:\n",
       "\n",
       "If \u001b[1;36m4\u001b[0m cooks can make \u001b[1;36m4\u001b[0m sandwiches in \u001b[1;36m4\u001b[0m minutes, then \u001b[1;36m8\u001b[0m cooks can make \u001b[1;36m8\u001b[0m sandwiches in \u001b[1;36m4\u001b[0m minutes.\n",
       "\n",
       "This is because the work rate per cook remains constant, and the number of cooks is simply doubled. Therefore, the \n",
       "time required to make \u001b[1;36m8\u001b[0m sandwiches remains the same, which is \u001b[1;36m4\u001b[0m minutes.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We can exploit this feature of chat models by unravelling a multi-step workflow in a conversation, turn by turn.\n",
    "\n",
    "problem = \"If it takes 4 cooks 4 minutes to make 4 sandwichs, how long would it take 8 cooks to make 8 sandwichs?\"\n",
    "\n",
    "with llm.session() as chat:\n",
    "\n",
    "    # Newly added reflection step:\n",
    "    chat.ask(\n",
    "        f\"Consider the following problem: {problem}\\n\\n\"\n",
    "        \"Please characterize the problem in abstract terms and identify potential pitfalls. \"\n",
    "        \"Don't solve the problem yet.\"\n",
    "    )\n",
    "    chat.ask(\"Now, solve the above problem, taking into account your reflections.\")\n",
    "    chat.ask(\"Please carefully assess and improve the solution provided.\")\n",
    "    answer = chat.ask(\"Finally, extract the answer from the revised solution.\")\n",
    "\n",
    "rich.print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summing up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lesson:\n",
    "\n",
    "1Ô∏è‚É£ We've seen how to prompt an LLM programmatically, i.e. via simple python code.\n",
    "\n",
    "2Ô∏è‚É£ We've used placeholders (`{}` and `{slot_name}`) to generalize prompts, and seen how to replace those abstract placeholders with a variable's value.\n",
    "\n",
    "3Ô∏è‚É£ We've used placeholders to build simple, linear pipelines by chaining LLM-instructions and using one step's output as next step's input.\n",
    "\n",
    "4Ô∏è‚É£ We've also implemented an LLM workflow where all steps see the entire previous history by emulating chats. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
